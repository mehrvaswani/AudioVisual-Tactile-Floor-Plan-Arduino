# AudioVisual-Tactile-Floor-Plan-Arduino
**Abstract** - The difficulty and fear of independent travel is a disabling consequence of blindness and vision impairment. The Royal National Institute of Blind People estimates that two million people in the UK suffer from significant sight loss and millions more struggle with standard print and signage, resulting in limited navigation and mobility. Advances in audio-based GPS navigation like Google Maps have massively helped the visually impaired navigate outdoor spaces but navigating indoor spaces where such audio navigation tools do not work is still fraught with challenges as the visually impaired have to rely on sighted partners for directions. Our audiovisual tactile interactive map allows users to anticipate the environment they will come across and gives them the confidence to explore a new place by considering a floor plan of a building which can be read by sight and heard by touch, keeping in mind ‘access for all’. The tactility of the map’s lines, patterns, braille lettering and large print, alongside the detailed audio feedback you receive while touching the map makes a visit to any public place more engaging, informative, and stimulating. The solution to greater independence and inclusion for visually impaired users is now at their fingertips.

**Interaction Overview** - Sighted people read maps regularly. Whether it is planning routes in the city, grasping global affairs and geographic separation, plan museum excursions or remembering the new office floorpan. Our use of maps and sense of what they represent is based almost entirely on looking at them. Navigating a new place without a map is almost foreign in this day and age - let alone having to do it without sight like most of the 285 million people (WHO, 2014) in the world who are visually impaired do everyday. Considering user preferences and behaviour is a necessity to developing accessible interaction for blind people. On the basis of the sensory compensation hypothesis (Heller and Ballesteros, 2012), whereby in the absence of
vision, the areas of the brain in blind people normally devoted to handling that sensory information is rewired to process and heighten other remaining senses (Bates, 2012), blind individuals rely on their sense of touch for pattern perception, much as the rest of us depend on vision. Therefore, this project incorporates a multi-sensory method of way finding for the blind by merging traditional (touch) and modern (capacitive sensing, audio) interactions. The top layer of the prototype is the traditional interaction that incorporates visual and tactile elements such as large print, raised lines and textures and braille lettering because tactility is essential in the knowledge transfer for blind people to communicate (Götzelmann, 2018). The bottom layer is the modern interaction that uses conductive paint and software manipulation for capacitive sensing and triggering audio playback. The conductive paint contains small traces of metal particles that pick up electrical signals from people’s fingers transmitting to the Arduino and connected to the software that controls the audio. Lightly touching or running your fingers over a specific location on the map will trigger audio playback indicating what the location is while a long press on that location will play an audio description of directions to that specific location from where the user is, providing access to information which improves spatial awareness. We implement the audio component for various reasons (1) using only Braille can limit a map’s effectiveness and is not an optimal use of space since it comes in only one large font size and variations of Braille exist according to level (Type I or Type II) and geography (2) Human-Computer Interactions researchers have emphasised that “tactile graphics can be overwhelming with tactile stimuli and information,” resulting in confusing diagrams and inadequate braille labels, and (3) not all visually impaired users read Braille (Brock and Jouffrais, 2015). A multi sensory interaction hence not only creates for a fuller, more wholesome experience but it also enables various kinds of visually impaired users to engage with an environment more independently. Interactive multimodal systems that combine auditory and
using an Audiovisual Tactile Map tactile modalities have also shown to be effective in nonvisual navigation (Geronazzo, Bedin, Brayda, Campus, & Avanzini, 2016). A pertinent use case for this map is for public transit but it is a cost-effective solution (~ £50) that can be implemented in various languages and placed near the entrances and stairs/elevators on every floor in a wide variety of buildings and venues such as exhibits or museums, leisure facilities, office buildings and shopping centres to replace existing floor plans that are largely designed for the sighted.
A second use case of this technology that merges modern and traditional interactions for the visually impaired is teaching young children how to read Braille (refer to video Demo2). Painting conductive ink under or over Braille lettering enables users to hear the letters or words out loud as they are reading them with their fingers without having to rely on a sighted partner for guidance.

https://github.com/mehrvaswani/AudioVisual-Tactile-Floor-Plan-Arduino/issues/1#issue-1244328658
